import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

train_accuracy_list = [0.41264, 0.51936, 0.60694, 0.70484, 0.74598, 0.77408, 0.81102, 0.80894, 0.84968, 0.85228, 0.86832, 0.85796, 0.88824, 0.8754, 0.89886, 0.8973, 0.88944, 0.90916, 0.90486, 0.91934, 0.91916, 0.92794, 0.9243, 0.91554, 0.93744, 0.94084, 0.93332, 0.93944, 0.93882, 0.94668, 0.9441, 0.94238, 0.94704, 0.94326, 0.9359, 0.95266, 0.93342, 0.94204, 0.9424, 0.9542, 0.94814, 0.94864, 0.92544, 0.94166, 0.94888, 0.95692, 0.9606, 0.95402, 0.9587, 0.96046, 0.94924, 0.95294, 0.94572, 0.95522, 0.94584, 0.94462, 0.99196, 0.9954, 0.99602, 0.99716, 0.99772, 0.99822, 0.99858, 0.99848, 0.9989, 0.9987, 0.99896, 0.99928, 0.9993, 0.99948, 0.99924, 0.99946, 0.99946, 0.99972, 0.9997, 0.99966, 0.99964, 0.99962, 0.99972, 0.9998, 0.99974, 0.99972, 0.99974, 0.99962, 0.99984, 0.9998, 0.99968, 0.99984, 0.9998, 0.99986, 0.99974, 0.9998, 0.99988, 0.9999, 0.99986, 0.99988, 0.99986, 0.99984, 0.9998, 0.99976, 0.99982, 0.9999, 0.99986, 0.99988, 0.99986, 0.99988, 0.99984, 0.99988, 0.99994, 0.9999, 0.99992, 0.99984, 0.99982, 0.9999, 0.99988, 0.99986, 0.99984, 0.99986, 0.9998, 0.99984]
test_accuracy_list = [0.4258, 0.5257, 0.606, 0.7021, 0.7441, 0.7715, 0.7975, 0.7992, 0.835, 0.8312, 0.8434, 0.8294, 0.8565, 0.8492, 0.865, 0.8646, 0.8562, 0.8695, 0.863, 0.8756, 0.8727, 0.886, 0.8832, 0.8724, 0.8862, 0.8929, 0.8835, 0.8891, 0.8841, 0.8955, 0.8869, 0.8839, 0.9, 0.8911, 0.8835, 0.9015, 0.8783, 0.8889, 0.8895, 0.9011, 0.8911, 0.8947, 0.8774, 0.8885, 0.8888, 0.894, 0.9048, 0.894, 0.8985, 0.8993, 0.8943, 0.8959, 0.8872, 0.8987, 0.8817, 0.8925, 0.9333, 0.9346, 0.9382, 0.9373, 0.9376, 0.9377, 0.9379, 0.9396, 0.9398, 0.9402, 0.94, 0.9389, 0.939, 0.9395, 0.9392, 0.9395, 0.9387, 0.9413, 0.9404, 0.9396, 0.9396, 0.9403, 0.9403, 0.9398, 0.9399, 0.94, 0.9408, 0.9399, 0.9401, 0.9409, 0.9409, 0.94, 0.9392, 0.9411, 0.9407, 0.9416, 0.9406, 0.9408, 0.9404, 0.9401, 0.9411, 0.9408, 0.9414, 0.9399, 0.9408, 0.9391, 0.9403, 0.9402, 0.9409, 0.9408, 0.9404, 0.9408, 0.9403, 0.9412, 0.9398, 0.9408, 0.941, 0.9414, 0.9405, 0.9409, 0.9405, 0.9401, 0.9407, 0.941]
lr_list = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001]
statistic_list = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.026907478692383715, 0.024279019539836882, 0.022313797252699073, 0.02239169569690133, 0.020702936839684816, 0.020200136549515062, 0.019610902007747094, 0.019293945721393164, 0.02007620595420577, 0.01976148094270868, 0.018647137870992002, 0.017129977509736598, 0.017607070170562008, 0.017725204373833948, 0.018028014802525107, 0.01738273917135818, 0.017154324697230564, 0.015402957298167074, 0.013834498846439006, 0.012509813431497855, 0.012273507023368456, 0.011697356869627088, 0.011698800453857856, 0.011423951340964194, 0.01143941905174738, 0.011304927619323463, 0.010976579951898756, 0.010659598137119974, 0.010651188195860431, 0.01088280037932219, 0.010458971775041789, 0.010424062712398232, 0.010141193833010041, 0.010544363803203805, 0.010178297111324536, 0.009777087191734117, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.001499577977743125, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.00285096237866097, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0012936051000357824, 0]
avg_loss_list = [765.0519478321075, 568.8472802639008, 460.2467452287674, 373.15658617019653, 307.47180539369583, 257.9168999195099, 226.93440982699394, 203.30310264229774, 186.93371045589447, 170.77158357203007, 156.1940929442644, 144.77443432807922, 135.55262602865696, 126.94151982665062, 118.92313994467258, 111.54730941355228, 109.45231460034847, 101.26989038288593, 97.51523248106241, 92.04106420278549, 89.48389981687069, 84.51433812081814, 81.72296351194382, 78.36769844591618, 77.18839230388403, 73.86917772144079, 70.8637666106224, 70.1966406814754, 68.68301355093718, 65.25383457168937, 65.1667089574039, 61.348662570118904, 61.684979636222124, 61.43886626884341, 58.01124657317996, 57.126812268048525, 56.87749847024679, 54.51432594284415, 55.9363507963717, 55.53708167001605, 52.00362164154649, 52.9031720161438, 50.57043405622244, 51.28381018154323, 49.80424482561648, 49.994613230228424, 49.96302615851164, 47.666874665766954, 48.7716376632452, 47.551476411521435, 44.523193415254354, 44.60340247116983, 46.831543542444706, 44.92248373478651, 44.79584245942533, 42.613208923488855, 19.657250222750008, 11.384949800092727, 9.1678429141175, 7.116109072463587, 5.694437782163732, 5.120795407565311, 4.831342761288397, 4.131917139049619, 3.7727184284012765, 3.353503623395227, 3.2069055180763826, 3.0286726789781824, 2.7730547243263572, 2.4423836122150533, 2.3822826017276384, 2.4889471980859526, 1.890189777535852, 1.816925200400874, 1.8713526991778053, 1.9427355869556777, 1.6854443652555346, 1.5757077134330757, 1.4675804575672373, 1.6345619997591712, 1.5082991360977758, 1.5844937664223835, 1.3665664089785423, 1.4120095784892328, 1.3590146218630252, 1.3565804793615825, 1.3331418161396869, 1.3686770859058015, 1.3723369895596988, 1.4290215422806796, 1.2350962671334855, 1.2631006761366734, 1.3100133938423824, 1.1976886028278386, 1.3419684070977382, 1.349836022942327, 1.2246219613880385, 1.2668700561625883, 1.3733581769338343, 1.3119198385102209, 1.3382323255646043, 1.2836419931554701, 1.2892103951890022, 1.1741679096303415, 1.2982924621610437, 1.171471562498482, 1.2340663802460767, 1.2804887404490728, 1.3472993747272994, 1.2073182161257137, 1.2109851114510093, 1.2419593177037314, 1.2867143946059514, 1.3146510947699426, 1.1801059409335721, 1.2363622917619068, 1.2335225971182808, 1.2513163453404559, 1.1408117679238785, 1.127863786474336]

###pre-settlement
epoch_num = [i for i in range(1,121)]
decreasing_epoch = [i+1 for i in range(len(lr_list)-1) if i+1 <= len(lr_list) if lr_list[i] != lr_list[i+1]]

###testing and training accuarcy
plt.figure()
plt.title('test accuracy vs epoch by SSM in ResNet18 on CIFAR10 with minstat100_tol0.01_mb_smooth')
plt.plot(test_accuracy_list, c="blue", label="testing accuracy")
plt.plot(train_accuracy_list, c="purple", label="training accuracy")
plt.axvline(x=decreasing_epoch[0], ymin=0, ymax=1, linestyle ="--", c="red", linewidth = 1, label="epochs when lr decreases")
for lr in decreasing_epoch[1:]:
  plt.axvline(x=lr, ymin=0, ymax=1, linestyle ="--", c="red", linewidth = 1)
for x,y in zip(decreasing_epoch,[train_accuracy_list[i] for i in decreasing_epoch]):
  plt.annotate(y,(x,y), textcoords="offset points", xytext=(0,10),ha='center')
for x,y in zip(decreasing_epoch,[test_accuracy_list[i] for i in decreasing_epoch]):
  plt.annotate(y,(x,y), textcoords="offset points", xytext=(0,10),ha='center')
plt.xlabel('number of epoch')
plt.ylabel('test accuracy')
plt.legend(shadow=True)
plt.show()

###learning rate
plt.figure()
plt.title('learning rate vs epoch by SSM in ResNet18 on CIFAR10 with minstat100_tol0.01_mb_smooth')
plt.plot(lr_list, label ="learning rate")
plt.axvline(x=decreasing_epoch[0], ymin=0, ymax=1, linestyle ="--", c="red", linewidth = 1, label="epochs when lr decreases")
for lr in decreasing_epoch[1:]:
  plt.axvline(x=lr, ymin=0, ymax=1, linestyle ="--", c="red", linewidth = 1)
for x,y in zip(decreasing_epoch,[lr_list[i] for i in decreasing_epoch]):
  plt.annotate(y,(x,y), textcoords="offset points", xytext=(0,10),ha='center')
plt.xlabel('number of epoch')
plt.ylabel('leanring rate')
plt.legend(shadow=True)
plt.show()

###statistic
tol = 0.01
ineffective_stat_y = [s for s in statistic_list if s != 0 and s >= tol]
ineffective_stat_x = [i+1 for i in range(len(statistic_list)) if  statistic_list[i]!= 0 and statistic_list[i] >= tol]
effective_stat_y = [s for s in statistic_list if s != 0 and s < tol]
effective_stat_x = [i+1 for i in range(len(statistic_list)) if  statistic_list[i]!= 0 and statistic_list[i] < tol]
plt.figure()
plt.title('statistic vs epoch by SSM in ResNet18 on CIFAR10 with minstat100_tol0.01_mb_smooth')
plt.scatter(ineffective_stat_x,ineffective_stat_y,linewidths = 0.001, c = "green", label = "stat when lr doesn't change")
plt.scatter(effective_stat_x,effective_stat_y,linewidths = 0.001, c = "red", label = "stat when lr decrease")
plt.plot([tol]*len(statistic_list), c = "gray", label = "tolerance level")
plt.xlabel("number of epoch")
plt.ylabel("statistic")
plt.legend(shadow=True)
plt.show()

###avg loss
plt.figure()
plt.title('avg loss vs epoch by SSM in ResNet18 on CIFAR10 with minstat100_tol0.01_mb_smooth')
plot = plt.plot(avg_loss_list, label="average loss")
plt.axvline(x=decreasing_epoch[0], ymin=0, ymax=1, linestyle ="--", c="red", linewidth = 1, label="epochs when lr decreases")
for lr in decreasing_epoch[1:]:
  plt.axvline(x=lr, ymin=0, ymax=1, linestyle ="--", c="red", linewidth = 1)
for x,y in zip(decreasing_epoch,[avg_loss_list[i] for i in decreasing_epoch]):
  plt.annotate("{:.2f}".format(y),(x,y), textcoords="offset points", xytext=(0,10),ha='center')
plt.xlabel('number of epoch')
plt.ylabel('avg loss')
plt.legend(shadow=True)
plt.show()
